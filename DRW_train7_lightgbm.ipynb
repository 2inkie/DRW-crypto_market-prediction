{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOTjEtzKnI0411uZefIJwAm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmzHivCGuMG-",
        "outputId": "b3582c25-8eb7-46ef-cc9f-d25427f9e86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: kneed in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from kneed) (1.15.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna kneed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, json, pickle, warnings, optuna, joblib\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from kneed import KneeLocator\n",
        "from lightgbm import LGBMRegressor\n",
        "from google.colab import drive\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from collections import defaultdict\n",
        "from scipy.stats import pearsonr, zscore\n",
        "from scipy.spatial.distance import squareform\n",
        "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram"
      ],
      "metadata": {
        "id": "Rp54DykEun3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.utils.deprecation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIy29X8MwCtK",
        "outputId": "49dd99d9-9a31-45ff-a9a9-d4f5ffab4921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "  def __init__(self, data_path, file_name):\n",
        "    self.data_path = data_path\n",
        "    self.file_name = file_name\n",
        "\n",
        "  def load(self):\n",
        "    df = pd.read_parquet(self.data_path + self.file_name)\n",
        "    self.df = df.loc[:, ~((df == -np.inf).any() | (df == 0).all())]\n",
        "    print('Data loaded')\n",
        "    return self\n",
        "\n",
        "  def train_split(self):\n",
        "    label = self.df['label']\n",
        "    qty_vol = self.df[['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume']]\n",
        "    X_ = self.df.drop(['label', 'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'], axis=1)\n",
        "    return X_, qty_vol, label\n",
        "\n",
        "  def test_split(self):\n",
        "    qty_vol = self.df[['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume']]\n",
        "    X_ = self.df.drop(['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'], axis=1)\n",
        "    return X_, qty_vol\n",
        "\n",
        "  def load_features_json_list(self):\n",
        "    with open(self.data_path + self.file_name, 'r') as f:\n",
        "      return json.load(f)\n",
        "\n",
        "  def load_clusters_pkl(self):\n",
        "    with open(self.data_path + self.file_name, 'rb') as f:\n",
        "      return pickle.load(f)"
      ],
      "metadata": {
        "id": "e-DRyqAOwJ8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureGenerator:\n",
        "  def __init__(self, df, epsilon=1e-6):\n",
        "    self.df = df\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def develop_features_from_qty_volume(self):\n",
        "    '''\n",
        "      Function to develop features from bid_qty, ask_qty, buy_qty, sell_qty\n",
        "      and volume columns.\n",
        "    '''\n",
        "    imbalance = (self.df['bid_qty'] - self.df['ask_qty']) / (self.df['bid_qty'] + self.df['ask_qty'] + self.epsilon)\n",
        "    buy_sell_ratio = np.log1p(self.df['buy_qty'] / (self.df['sell_qty'] + self.epsilon))\n",
        "    volume_z = zscore(self.df['volume'])\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'imbalance': imbalance,\n",
        "        'buy_sell_ratio': buy_sell_ratio,\n",
        "        'volume_z': volume_z\n",
        "        }, index=self.df.index)\n",
        "\n",
        "  def standardize_columns(self, columns):\n",
        "    '''Function to standardize specific columns wihtin a df.'''\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(self.df[columns])\n",
        "    df_scaled = pd.DataFrame(df_scaled, columns=columns, index=self.df.index)\n",
        "    return pd.concat([df_scaled, self.df['label']], axis=1)\n",
        "\n",
        "  def standardize_df(self):\n",
        "    '''Function to standardize a whole df.'''\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(self.df)\n",
        "    return pd.DataFrame(df_scaled, columns=self.df.columns, index=self.df.index)"
      ],
      "metadata": {
        "id": "CYs_Q80gwN3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LagCreator:\n",
        "  def __init__(self, lag_periods = 5):\n",
        "    self.lag_periods = lag_periods\n",
        "\n",
        "  def lag_features(self, X):\n",
        "\n",
        "    lagged_columns = []\n",
        "    for col in X.columns:\n",
        "        for lag in range(1, self.lag_periods + 1):\n",
        "          shifted = X[col].shift(lag)\n",
        "          shifted.name = f\"{col}_lag{lag}\"\n",
        "          lagged_columns.append(shifted)\n",
        "\n",
        "    lagged = pd.concat(lagged_columns, axis=1)\n",
        "    lagged = pd.concat([X, lagged], axis=1)\n",
        "    return lagged.dropna()\n",
        "\n",
        "  def match_index_lags(self, X_lagged, Y):\n",
        "    '''Y is series with a single column'''\n",
        "    y_lagged = Y.loc[X_lagged.index]\n",
        "\n",
        "    return y_lagged\n"
      ],
      "metadata": {
        "id": "PBf3r_DiwUkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureLagSelector:\n",
        "    def __init__(self, feature_list):\n",
        "        '''\n",
        "        Initialize the selector with a list of desired features.\n",
        "        Features can be raw (e.g., 'X264') or lagged (e.g., 'X264_lag2')\n",
        "        '''\n",
        "        self.feature_list = feature_list\n",
        "        self.selected_features = {}\n",
        "\n",
        "    def _parse_feature(self, feature_name):\n",
        "\n",
        "        '''Parse feature name into base column and lag value (if present).'''\n",
        "\n",
        "        if '_lag' in feature_name:\n",
        "            base, lag = feature_name.split('_lag')\n",
        "            return base, int(lag)\n",
        "        return feature_name, None\n",
        "\n",
        "    def _transform(self, df):\n",
        "        '''Build a new DataFrame with the selected and lagged features.'''\n",
        "\n",
        "        self.selected_features.clear()\n",
        "        for feature in self.feature_list:\n",
        "            base, lag = self._parse_feature(feature)\n",
        "            if base not in df.columns:\n",
        "                print(f\"Base column '{base}' not found in DataFrame\")\n",
        "                continue\n",
        "            if lag is None:\n",
        "                self.selected_features[feature] = df[base]\n",
        "            else:\n",
        "                self.selected_features[feature] = df[base].shift(lag)\n",
        "\n",
        "        return pd.DataFrame(self.selected_features)\n",
        "\n",
        "    def fit_transform(self, df):\n",
        "        return self._transform(df)\n"
      ],
      "metadata": {
        "id": "WBRFvk31waph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelPipelineOptimizerLGB:\n",
        "  def __init__ (self, y, df, features2, clusters_components, model_save_location, model_name):\n",
        "    self.df = df\n",
        "    self.features2 = features2\n",
        "    self.y = y\n",
        "    self.clusters_components = clusters_components\n",
        "    self.data_path = model_save_location\n",
        "    self.model_name = model_name\n",
        "\n",
        "    self.best_features = [f for group in self.clusters_components[0] for f in group]\n",
        "    self.X = FeatureLagSelector(self.best_features).fit_transform(self.df).dropna()\n",
        "    self.features2 = LagCreator(3).lag_features(self.features2)\n",
        "\n",
        "    self.X = pd.concat([self.X, self.features2], axis=1)\n",
        "\n",
        "    self.y = self.y.loc[self.X.index]\n",
        "\n",
        "\n",
        "    del self.df, self.features2\n",
        "    gc.collect()\n",
        "\n",
        "  def create_column_transformer(self):\n",
        "    feature_clusters, pca_components = self.clusters_components\n",
        "    transformers = []\n",
        "\n",
        "    for i, (features, n_comp) in enumerate(zip(feature_clusters, pca_components)):\n",
        "      if len(features) == 1:\n",
        "            # For single feature, just apply StandardScaler\n",
        "            pipe = Pipeline([\n",
        "                ('scaler', StandardScaler())\n",
        "            ])\n",
        "      else:\n",
        "            # Multiple features: apply scaler + PCA\n",
        "            pipe = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('pca', PCA(n_components=n_comp))\n",
        "            ])\n",
        "      transformers.append((f'cluster_{i}', pipe, features))\n",
        "\n",
        "    return ColumnTransformer(transformers, remainder='passthrough')\n",
        "\n",
        "  def objective(self, trial):\n",
        "    lgb_params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"objective\": \"regression\",\n",
        "        \"verbosity\": -1\n",
        "        }\n",
        "\n",
        "\n",
        "    col_transformer = self.create_column_transformer()\n",
        "    tscv = TimeSeriesSplit(n_splits=10)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in tscv.split(self.X):\n",
        "      X_train, X_val = self.X.iloc[train_idx], self.X.iloc[val_idx]\n",
        "      y_train, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]\n",
        "\n",
        "      pipeline = Pipeline([\n",
        "          ('pca_clusters', col_transformer),\n",
        "          ('lgb', LGBMRegressor(**lgb_params))\n",
        "      ])\n",
        "\n",
        "      pipeline.fit(X_train, y_train)\n",
        "      preds = pipeline.predict(X_val)\n",
        "\n",
        "      corr, _ = pearsonr(y_val, preds)\n",
        "      scores.append(corr)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "  def optimize(self, n_trials=50):\n",
        "    self.study = optuna.create_study(direction=\"maximize\")\n",
        "    self.study.optimize(self.objective, n_trials=n_trials, n_jobs=-1)\n",
        "\n",
        "    print(\"\\nBest trial:\")\n",
        "    print(f\"  Pearson correlation: {self.study.best_value:.4f}\")\n",
        "    print(\"  Hyperparameters:\")\n",
        "    for key, val in self.study.best_params.items():\n",
        "        print(f\"    {key}: {val}\")\n",
        "\n",
        "    # Visualize optimization\n",
        "    optuna.visualization.plot_optimization_history(self.study).show()\n",
        "    optuna.visualization.plot_param_importances(self.study).show()\n",
        "\n",
        "    # Recreate PCA + scaler transformer\n",
        "    col_transformer = self.create_column_transformer()\n",
        "\n",
        "    # Build final pipeline with best LGB params\n",
        "    best_params = self.study.best_params.copy()\n",
        "    best_params.update({\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"objective\": \"regression\",\n",
        "        \"verbosity\": -1\n",
        "        })\n",
        "\n",
        "    final_pipeline = Pipeline([\n",
        "        ('pca_clusters', col_transformer),\n",
        "        ('lgb', LGBMRegressor(**best_params))\n",
        "    ])\n",
        "\n",
        "    # Fit final pipeline on all data\n",
        "    final_pipeline.fit(self.X, self.y)\n",
        "\n",
        "    # Save pipeline\n",
        "    joblib.dump(final_pipeline, self.data_path + self.model_name)\n",
        "    print(f\"\\nModel saved to: {self.data_path + self.model_name}\")\n",
        "\n",
        "    return final_pipeline"
      ],
      "metadata": {
        "id": "u3tPwbx6whLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "# Group 1 - X1, X2 ....\n",
        "# Group 2 - _qty, vol"
      ],
      "metadata": {
        "id": "mmM3Ejm30IJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filepaths\n",
        "dataPathLoad = '/content/drive/MyDrive/Colab Notebooks/DRW/data/'\n",
        "dataPathSave = '/content/drive/MyDrive/Colab Notebooks/DRW/data/v7'\n",
        "fileNameTrain = 'train.parquet'"
      ],
      "metadata": {
        "id": "g13OZkhV0Jzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data and remove -inf columns and columns full of 0\n",
        "loader = DataLoader(dataPathLoad, fileNameTrain)\n",
        "features_group1, features_group2, label = loader.load().train_split()\n",
        "del loader\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpMJ_8k70LKb",
        "outputId": "f99ea119-3dca-44b0-da4e-bf272376e737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the right features2\n",
        "features_group2 = FeatureGenerator(features_group2).develop_features_from_qty_volume()\n"
      ],
      "metadata": {
        "id": "wPVGP50U0NS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the groups\n",
        "with open(dataPathSave + 'PCA_components7.json', 'r') as f:\n",
        "    groups_components = json.load(f)"
      ],
      "metadata": {
        "id": "CFCSk03T0O2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize and save model\n",
        "optimizer = ModelPipelineOptimizerLGB(label, features_group1, features_group2, groups_components, dataPathSave, 'model7_10splits_LGB.pkl')\n",
        "final_pipeline = optimizer.optimize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiaq34Tz0QZi",
        "outputId": "57d42b3f-8f16-4d2c-ad90-3a15dbd3325b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 14:59:02,306] A new study created in memory with name: no-name-9c969c04-689e-474d-974b-4fdf0389161d\n",
            "[I 2025-06-07 15:22:55,682] Trial 3 finished with value: 0.00982035573026647 and parameters: {'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.004047000888822234, 'subsample': 0.9377602343470091, 'colsample_bytree': 0.6620154271155032, 'num_leaves': 78, 'min_child_samples': 16, 'reg_alpha': 2.2979574028050873, 'reg_lambda': 0.4345119249561048}. Best is trial 3 with value: 0.00982035573026647.\n",
            "[I 2025-06-07 15:23:19,025] Trial 5 finished with value: 0.030173618092506016 and parameters: {'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.007014923996247437, 'subsample': 0.9458060317127609, 'colsample_bytree': 0.5438642663394593, 'num_leaves': 115, 'min_child_samples': 87, 'reg_alpha': 0.003957447778671953, 'reg_lambda': 4.22884782638347}. Best is trial 5 with value: 0.030173618092506016.\n",
            "[I 2025-06-07 15:24:59,670] Trial 0 finished with value: 0.044411801016120425 and parameters: {'n_estimators': 291, 'max_depth': 6, 'learning_rate': 0.003943730173806672, 'subsample': 0.5893450271852156, 'colsample_bytree': 0.4821179099898674, 'num_leaves': 52, 'min_child_samples': 97, 'reg_alpha': 0.22850230533993932, 'reg_lambda': 0.33259152443137074}. Best is trial 0 with value: 0.044411801016120425.\n",
            "[I 2025-06-07 15:24:59,842] Trial 4 finished with value: 0.0421944633055352 and parameters: {'n_estimators': 414, 'max_depth': 4, 'learning_rate': 0.009670867832741523, 'subsample': 0.9435736561784711, 'colsample_bytree': 0.8362246880952, 'num_leaves': 68, 'min_child_samples': 75, 'reg_alpha': 1.37014119392285, 'reg_lambda': 0.0011035412668698268}. Best is trial 0 with value: 0.044411801016120425.\n",
            "[I 2025-06-07 15:26:10,579] Trial 2 finished with value: 0.03583856365281067 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.0020738619330384297, 'subsample': 0.516790968577883, 'colsample_bytree': 0.48860475689100047, 'num_leaves': 24, 'min_child_samples': 35, 'reg_alpha': 0.037647528754205385, 'reg_lambda': 6.113718973252179}. Best is trial 0 with value: 0.044411801016120425.\n",
            "[I 2025-06-07 15:27:14,904] Trial 7 finished with value: 0.05364846542183314 and parameters: {'n_estimators': 286, 'max_depth': 7, 'learning_rate': 0.010522341093109908, 'subsample': 0.6459918959487438, 'colsample_bytree': 0.548537989614652, 'num_leaves': 31, 'min_child_samples': 89, 'reg_alpha': 7.166366390475761, 'reg_lambda': 3.8347812505074006}. Best is trial 7 with value: 0.05364846542183314.\n",
            "[I 2025-06-07 15:27:15,339] Trial 6 finished with value: 0.017523176406770088 and parameters: {'n_estimators': 133, 'max_depth': 10, 'learning_rate': 0.001428247806516335, 'subsample': 0.8618377981209423, 'colsample_bytree': 0.8747487540881355, 'num_leaves': 108, 'min_child_samples': 96, 'reg_alpha': 0.03215942045540827, 'reg_lambda': 0.0016328509620545959}. Best is trial 7 with value: 0.05364846542183314.\n",
            "[I 2025-06-07 15:32:06,460] Trial 1 finished with value: 0.059723862975076425 and parameters: {'n_estimators': 452, 'max_depth': 7, 'learning_rate': 0.014040639656483342, 'subsample': 0.6987287116484584, 'colsample_bytree': 0.7084966748930233, 'num_leaves': 132, 'min_child_samples': 26, 'reg_alpha': 0.002820394234467344, 'reg_lambda': 0.0010835187795074077}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:50:58,381] Trial 10 finished with value: 0.05545377418195223 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.09566552287781836, 'subsample': 0.7198501524768943, 'colsample_bytree': 0.9061293966750017, 'num_leaves': 53, 'min_child_samples': 49, 'reg_alpha': 0.05024300689372753, 'reg_lambda': 0.032772843339531614}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:50:58,930] Trial 9 finished with value: 0.023823563555348225 and parameters: {'n_estimators': 377, 'max_depth': 6, 'learning_rate': 0.0012951596829449993, 'subsample': 0.5144485345954997, 'colsample_bytree': 0.9945405292582705, 'num_leaves': 118, 'min_child_samples': 45, 'reg_alpha': 0.18414394988888008, 'reg_lambda': 0.3997969676034224}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:51:16,807] Trial 11 finished with value: 0.05473310885413637 and parameters: {'n_estimators': 330, 'max_depth': 4, 'learning_rate': 0.04069277260742816, 'subsample': 0.855470300497543, 'colsample_bytree': 0.6719191890380722, 'num_leaves': 135, 'min_child_samples': 32, 'reg_alpha': 2.676567560056069, 'reg_lambda': 4.220495945735136}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:51:22,597] Trial 8 finished with value: 0.030841019805121727 and parameters: {'n_estimators': 216, 'max_depth': 11, 'learning_rate': 0.0031357335881318322, 'subsample': 0.6213855863207682, 'colsample_bytree': 0.849556785945481, 'num_leaves': 112, 'min_child_samples': 91, 'reg_alpha': 2.321192537639689, 'reg_lambda': 0.401108291358665}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:53:47,861] Trial 12 finished with value: 0.02845971081612215 and parameters: {'n_estimators': 60, 'max_depth': 4, 'learning_rate': 0.013333224566605004, 'subsample': 0.7163671691902261, 'colsample_bytree': 0.70769228307091, 'num_leaves': 102, 'min_child_samples': 42, 'reg_alpha': 0.0016772966809952372, 'reg_lambda': 0.004847257454713769}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 15:59:10,316] Trial 14 finished with value: 0.04726631986611293 and parameters: {'n_estimators': 489, 'max_depth': 8, 'learning_rate': 0.002348071142555929, 'subsample': 0.6424918015054986, 'colsample_bytree': 0.7843558441834098, 'num_leaves': 43, 'min_child_samples': 66, 'reg_alpha': 8.509145675357537, 'reg_lambda': 0.03177813731271572}. Best is trial 1 with value: 0.059723862975076425.\n",
            "[I 2025-06-07 16:01:08,217] Trial 13 finished with value: 0.06638623939861832 and parameters: {'n_estimators': 483, 'max_depth': 11, 'learning_rate': 0.02292562618001291, 'subsample': 0.5840195299890206, 'colsample_bytree': 0.48279077797569575, 'num_leaves': 86, 'min_child_samples': 16, 'reg_alpha': 4.885941267875627, 'reg_lambda': 0.01620010962337001}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:09:33,488] Trial 15 finished with value: 0.0579136547960189 and parameters: {'n_estimators': 479, 'max_depth': 6, 'learning_rate': 0.04592188982018562, 'subsample': 0.941526234960113, 'colsample_bytree': 0.7804508143638349, 'num_leaves': 96, 'min_child_samples': 70, 'reg_alpha': 1.0360824493764254, 'reg_lambda': 7.943556571122965}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:32:50,247] Trial 16 finished with value: 0.05943171289785345 and parameters: {'n_estimators': 471, 'max_depth': 6, 'learning_rate': 0.03810733145549225, 'subsample': 0.593927970081986, 'colsample_bytree': 0.6432372002478027, 'num_leaves': 128, 'min_child_samples': 54, 'reg_alpha': 0.21070078540077047, 'reg_lambda': 6.326838442733319}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:40:00,931] Trial 19 finished with value: 0.06269443604646513 and parameters: {'n_estimators': 488, 'max_depth': 8, 'learning_rate': 0.0661686738554535, 'subsample': 0.7327902875453645, 'colsample_bytree': 0.7613412990739485, 'num_leaves': 146, 'min_child_samples': 62, 'reg_alpha': 0.0015413938542327872, 'reg_lambda': 0.01189944593812191}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:41:30,639] Trial 17 finished with value: 0.06596321096413002 and parameters: {'n_estimators': 491, 'max_depth': 9, 'learning_rate': 0.03368932475596567, 'subsample': 0.7977922051269469, 'colsample_bytree': 0.7102058577529999, 'num_leaves': 146, 'min_child_samples': 6, 'reg_alpha': 0.0012245095006146337, 'reg_lambda': 0.01603014541516691}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:44:27,334] Trial 18 finished with value: 0.053650285277965004 and parameters: {'n_estimators': 490, 'max_depth': 8, 'learning_rate': 0.06984244084373997, 'subsample': 0.7246198770388087, 'colsample_bytree': 0.8044351577107589, 'num_leaves': 146, 'min_child_samples': 59, 'reg_alpha': 0.001021130006183057, 'reg_lambda': 0.010823477473182895}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:46:04,107] Trial 20 finished with value: 0.056000551619875674 and parameters: {'n_estimators': 433, 'max_depth': 8, 'learning_rate': 0.0828475720764163, 'subsample': 0.7420219868442447, 'colsample_bytree': 0.939321778346957, 'num_leaves': 144, 'min_child_samples': 64, 'reg_alpha': 0.009402288112698807, 'reg_lambda': 0.014219696339261335}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:53:25,888] Trial 22 finished with value: 0.05967279893857278 and parameters: {'n_estimators': 498, 'max_depth': 9, 'learning_rate': 0.028614774495353764, 'subsample': 0.7881522416037421, 'colsample_bytree': 0.6069685933658484, 'num_leaves': 150, 'min_child_samples': 8, 'reg_alpha': 0.00783702316524275, 'reg_lambda': 0.006650076776794115}. Best is trial 13 with value: 0.06638623939861832.\n",
            "[I 2025-06-07 16:56:59,125] Trial 21 finished with value: 0.054350314161605275 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.09156325277094678, 'subsample': 0.7831179695227938, 'colsample_bytree': 0.99608456353493, 'num_leaves': 150, 'min_child_samples': 12, 'reg_alpha': 0.008659537221262965, 'reg_lambda': 0.01860247231187244}. Best is trial 13 with value: 0.06638623939861832.\n"
          ]
        }
      ]
    }
  ]
}